{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "POA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl0fuXiHs-2f",
        "cellView": "form"
      },
      "source": [
        "# @title Modules \n",
        "# Mounting Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "\n",
        "# Keras modules\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Convolution2D, Flatten, MaxPooling2D, ZeroPadding2D, Dropout, BatchNormalization, Activation, DepthwiseConv2D, SeparableConv2D\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, RemoteMonitor, TensorBoard, ReduceLROnPlateau, History, EarlyStopping\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "import keras.backend as K\n",
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "#General\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import datetime\n",
        "import os\n",
        "import pickle\n",
        "from scipy.stats import mode\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGUzHBGZX7Jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8388e018-a47d-40be-95d4-cc96016dd723"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkREgrGruQUn",
        "outputId": "6a9f1b84-ada9-46ff-f4b9-d79685b6c3bd"
      },
      "source": [
        "# @title Git Pull\n",
        "%cd /content/drive/MyDrive/EPFL Account/ML Project 2/ml_project2\n",
        "! git reset --hard \n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EPFL Account/ML Project 2/ml_project2\n",
            "^C\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OEM9f07uD3d",
        "outputId": "fcb356e5-e9a5-4e4a-aa37-9b3a6d1b3ff7"
      },
      "source": [
        "# @title Import our modules\n",
        "%cd /content/drive/MyDrive/EPFL Account/ML Project 2/ml_project2/src\n",
        "# specify the githum repo location as .../ml_project2/src\n",
        "\n",
        "#Our Modules\n",
        "import sound_processing as sp\n",
        "from utils import*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EPFL Account/ML Project 2/ml_project2/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-L1z8gEuRWN",
        "outputId": "09c6b2c8-e5a8-45c0-e280-215259c7f4fc"
      },
      "source": [
        "# @title Check the files\n",
        "%cd /content/drive/MyDrive/ML Project 2/ml_project2/src\n",
        "!ls -l ./npz_files/*/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/ML Project 2/ml_project2/src'\n",
            "/content/drive/MyDrive/EPFL Account/ML Project 2/ml_project2/src\n",
            "./npz_files/GVA/:\n",
            "total 3079312\n",
            "-rw------- 1 root root  553904757 Nov 27 16:23 GVA_Ca_Co_test.npz\n",
            "-rw------- 1 root root 1369343627 Nov 27 16:16 GVA_Ca_train_b1.npz\n",
            "-rw------- 1 root root 1229965595 Nov 27 16:13 GVA_Co_train_b1.npz\n",
            "\n",
            "./npz_files/POA/:\n",
            "total 21056243\n",
            "-rw------- 1 root root  546407225 Nov 28 07:42 POA_Ca_Co_test.npz\n",
            "-rw------- 1 root root 4121620181 Nov 27 15:29 POA_Ca_train_b1.npz\n",
            "-rw------- 1 root root 4301549167 Nov 27 15:17 POA_Ca_train_b2.npz\n",
            "-rw------- 1 root root 4519848135 Nov 27 15:41 POA_Ca_train_b3.npz\n",
            "-rw------- 1 root root 4150727343 Nov 27 15:52 POA_Ca_train_b4.npz\n",
            "-rw------- 1 root root 3088366560 Nov 27 16:07 POA_Co_train_b1.npz\n",
            "-rw------- 1 root root  833071644 Nov 27 15:57 POA_Co_train_b2.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ShT16tDucJd",
        "cellView": "form"
      },
      "source": [
        "# @title Generator\n",
        "def generator(x_train, y_train, x_test, y_test):\n",
        "\n",
        "  #Generates augmented data, we don't use it.\n",
        "\n",
        "  train_batch_size = 32\n",
        "  train_steps = x_train.shape[0]//train_batch_size # need to specify the number of steps since the data generator outputs continuously\n",
        "\n",
        "\n",
        "\n",
        "  train_generator = ImageDataGenerator(width_shift_range=10,\n",
        "                                       samplewise_center=False, \n",
        "                                       samplewise_std_normalization=False,\n",
        "                                       featurewise_center=False,\n",
        "                                       featurewise_std_normalization=False,\n",
        "                                       #zoom_range=[1/1.3, 1.3],\n",
        "                              #height_shift_range=4,\n",
        "                              )\n",
        "\n",
        "  test_generator = ImageDataGenerator(samplewise_center=False, \n",
        "                                       samplewise_std_normalization=False,\n",
        "                                      featurewise_center=False,\n",
        "                                      featurewise_std_normalization=False)\n",
        "\n",
        "  train_generator.fit(x_train) #apply the augmetnation to train data\n",
        "  test_generator.fit(x_test)\n",
        "  train_datagen = train_generator.flow(x_train, y_train, batch_size=train_batch_size) # creates the mii batch flow\n",
        "  test_datagen = test_generator.flow(x_test, y_test, batch_size=train_batch_size) \n",
        "\n",
        "  return train_datagen, test_datagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZbUw6mWujE4",
        "cellView": "form"
      },
      "source": [
        "# @title Plotters\n",
        "def add_subplot(history, fig, size, i, *name):\n",
        "    print('Adding plot')\n",
        "    Title = 'Run' + str(i) \n",
        "    ax = fig.add_subplot(math.ceil(size/2), 2, i)\n",
        "    ax.plot(history.history['accuracy'])\n",
        "    ax.plot(history.history['val_accuracy'])\n",
        "    ax.plot(history.history['loss'])\n",
        "    ax.plot(history.history['val_loss'])\n",
        "    ax.set_title(Title)\n",
        "    ax.set_ylabel('accuracy / loss')\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train_acc', 'test_acc', 'train_loss', 'test_loss'], loc='lower left')\n",
        "    ax.set_ylim(ymax=1, ymin=0)\n",
        "    #plt.savefig(name + '.png')\n",
        "\n",
        "def Plot_history(history , name, title='model accuracy / loss'):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(title)\n",
        "  plt.ylabel('accuracy / loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train_acc', 'test_acc','train_loss','test_loss'], loc='lower left')\n",
        "  plt.ylim(ymax = 1, ymin = 0)\n",
        "  plt.savefig(name + '.png')\n",
        "  plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT1O5tpmu5do",
        "cellView": "form"
      },
      "source": [
        "# @title Model\n",
        "def def_model(shape):\n",
        "  dense = 25\n",
        "  model = Sequential()\n",
        "\n",
        "\n",
        "  #model.add(Convolution2D(5, (1, 1), activation='relu', padding='same', input_shape=shape, data_format='channels_last') )\n",
        "  #model.add(BatchNormalization())\n",
        "  #model.add(MaxPooling2D(2, 2))\n",
        "  #model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(15, (3, 3), activation='relu', padding='same', input_shape=shape, data_format='channels_last') )\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(30, (3, 3), activation='relu', padding='same', input_shape=shape, data_format='channels_last'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Convolution2D(5, (1, 1), activation='relu', padding='same', input_shape=shape, data_format='channels_last') )\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(dense, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  \n",
        "  return model\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY9-u7JyuzV6",
        "cellView": "form"
      },
      "source": [
        "# @title Callbacks\n",
        "def callbacks(run=''):\n",
        "  \"\"\"Created callbacks for the model. Early stopper, save best model only,\n",
        "  log results, reduce learning rate.\"\"\"\n",
        "  time = datetime.datetime.now().strftime(\"-%Y-%m-%d\") \n",
        "\n",
        "  dense = 25\n",
        "  checkpointer = ModelCheckpoint(monitor='val_loss', # automatically saves the model \n",
        "                               mode='auto', \n",
        "                               filepath= './models/TRAIN_ON_POA_BATCH_1_RUN_' + str(run)+'_' + time + '.h5',\n",
        "                               verbose=0,\n",
        "                               save_best_only=True,\n",
        "                               save_freq = 'epoch'\n",
        "                              )\n",
        "  csv_logger = CSVLogger('./models/TRAIN_ON_POA_BATCH_1_RUN_' + str(run) + '_' + time + '.txt') # saves the output log in csv\n",
        "\n",
        "  lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, # can be used to reduce the learning rate once the model stops learning\n",
        "                       min_delta=0.001, cooldown=1,\n",
        "                       verbose=0, patience=10,\n",
        "                        min_lr=4.0e-7)\n",
        "  early = EarlyStopping(monitor='val_loss',\n",
        "                        min_delta=0.002,\n",
        "                        patience=20,\n",
        "                        verbose=0,\n",
        "                        mode='auto', \n",
        "                        baseline=None,\n",
        "                        restore_best_weights=False\n",
        ")\n",
        "\n",
        "\n",
        "  return checkpointer, csv_logger, lr, early\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97xuMe7SvExp",
        "cellView": "form"
      },
      "source": [
        "# @title Train Model\n",
        "def train(x_train, y_train, x_test, y_test, run=''):\n",
        "  \"\"\"Trains model and returns the history object\"\"\"\n",
        "  \n",
        "\n",
        "  #train_datagen, test_datagen = generator(x_train, y_train, x_test, y_test)\n",
        "  shape = x_train.shape[1:]\n",
        "\n",
        "\n",
        "\n",
        "  model = def_model(shape) # load the defined model\n",
        "  #model = keras.models.load_model('./models/TRAIN_ON_POA_BATCH_1/TRAIN_ON_POA_BATCH_1_RUN_7_-2020-12-12.h5', custom_objects={'f1': f1})\n",
        "  # loads the pretrained model for transfer learning\n",
        "\n",
        "  sgd = optimizers.SGD(lr=0.00004, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  # define gradient descent \n",
        "\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy', f1])\n",
        "  # compile model\n",
        "\n",
        "  cb1, cb2, cb3, cb4 = callbacks(run)\n",
        "   \n",
        "  train_batch_size = 32\n",
        "  train_steps = x_train.shape[0]//train_batch_size # need to specify the number of steps since the data generator outputs continuously\n",
        "  #FitTheModel\n",
        "\n",
        "  history = model.fit(x_train, y_train,\n",
        "                      steps_per_epoch=train_steps,\n",
        "                      epochs=200,\n",
        "                      validation_data=(x_test, y_test),\n",
        "                      callbacks=[cb1, cb2, cb3, cb4, TqdmCallback(verbose=0)],\n",
        "                      verbose=0\n",
        "                      )\n",
        "  \n",
        "  max_val_acc = max(history.history['val_accuracy'])\n",
        "  min_val_loss = min(history.history['val_loss'])\n",
        "  max_val_f1 = max(history.history['val_f1'])\n",
        "  print('Min val_loss = {}, Max val_acc = {}, Max val_f1 = {}'.format(min_val_loss, max_val_acc, max_val_f1))\n",
        "  \n",
        "  return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0BgE1_pvIGG"
      },
      "source": [
        "def train_and_plot():\n",
        "\n",
        "  stat = []\n",
        "  fig = plt.figure(figsize=(15, 30))\n",
        "  N = 10\n",
        "  \n",
        "  x_train, y_train, x_test, y_test = get_arrays_POA(batch=1)\n",
        "  #for GVA replace the POA(batch=1) with GVA(), for other batches replace 1 \n",
        "  #with the batch number\n",
        "\n",
        "  print(x_train.shape)\n",
        "\n",
        "  for n in range(1, N):\n",
        "    print('Run' + str(n))\n",
        "    history = train(x_train, y_train, x_test, y_test, str(n))\n",
        "    #Plot_history(history, 'stft of all positions stacked', title='stft of all positions stacked model accuracy_small_4_1DFilter / loss')\n",
        "    stat.append((min(history.history['val_loss']), max(history.history['val_accuracy']), max(history.history['val_f1'])))\n",
        "\n",
        "    plt.suptitle('Trained on POA Batch 1')\n",
        "    #name = \"Intermediate_stft_3\"\n",
        "    add_subplot(history, fig, N, n)\n",
        "  \n",
        "  #plt.savefig('TRAIN_ON_POA_BATCH_1.pdf')                              \n",
        "  plt.show()\n",
        "\n",
        "  for i in np.arange(len(stat)):\n",
        "    plt.bar(i+1 + -0.25, stat[i][0], color = 'r', width = 0.25)\n",
        "    plt.bar(i+1 + 0., stat[i][1], color = 'b', width = 0.25)\n",
        "    plt.bar(i+1 + 0.25, stat[i][2], color = 'gold', width = 0.25)\n",
        "\n",
        "  plt.title('Trained on POA Batch 1')\n",
        "  plt.legend(['test_loss', 'test_acc','test_f1'], loc='lower left')\n",
        "  plt.xlabel('Run')\n",
        "  plt.ylim(top=1)\n",
        "  #plt.savefig('TRAIN_ON_POA_BATCH_1_HIST.pdf')\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "\n",
        "train_and_plot()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHPyj9GgFKk5"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYAtEkUz4P0A"
      },
      "source": [
        "def load_and_predict_GVA():\n",
        "  print('Loading the model')\n",
        "  model = keras.models.load_model('./models/TRAIN_ON_GVA_REM_POS_9/TRAIN_ON_GVA_TFINAL_RUN_3_-2020-12-12.h5', custom_objects={'f1': f1}) # best model preloaded\n",
        "  print('Loading data for GVA') \n",
        "  x_train, y_train, _, _ = get_arrays_GVA()\n",
        "  print('Done creating arrays for GVA ')\n",
        "  sgd = optimizers.SGD(lr=0.00004, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy', f1])\n",
        "  print('Predicting on GVA ')\n",
        "  score = model.evaluate(x_train, y_train, batch_size = 32)\n",
        "  for i in range(3):\n",
        "    print(model.metrics_names[i],  '%.4f' %  score[i])\n",
        "load_and_predict_GVA()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO76lCdyKEB6"
      },
      "source": [
        "def load_and_predict_POA(batch):\n",
        "  \"\"\"Load the pretrained model and predict on unseen data from POA\"\"\"\n",
        "  print('Loading the model')\n",
        "  model = keras.models.load_model('./models/TRAIN_ON_POA_BATCH_1/TRAIN_ON_POA_BATCH_1_RUN_7_-2020-12-12.h5', custom_objects={'f1': f1}) #  best model preloaded\n",
        "  print('Loading data for batch ' + str(batch))\n",
        "  x_train, y_train, _, _ = get_arrays_POA(batch)\n",
        "  print('Done creating arrays for batch ' + str(batch))\n",
        "  sgd = optimizers.SGD(lr=0.00004, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy', f1])\n",
        "  print('Predicting on batch ' + str(batch))\n",
        "  score = model.evaluate(x_train, y_train, batch_size = 32)\n",
        "  for i in range(3):\n",
        "    print(model.metrics_names[i],  '%.4f' %  score[i])\n",
        "\n",
        "load_and_predict_POA(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eX6J0xfGF9T",
        "outputId": "c566c92b-a90b-43a1-ab29-78833f95f650"
      },
      "source": [
        "def print_stat():\r\n",
        "  \"\"\"Loads the model logs, prints average statistics and the best model num\"\"\"\r\n",
        "  full_path  = 'models/TRAIN_ON_POA_BATCH_2' #specify the path of logs\r\n",
        "\r\n",
        "\r\n",
        "  val_loss = []\r\n",
        "  val_acc = []  \r\n",
        "  val_f1 = []\r\n",
        "  for file in os.listdir(full_path):\r\n",
        "    if file.endswith(\".txt\"):\r\n",
        "      acc, f1, loss = np.loadtxt(os.path.join(full_path, file), delimiter=',', skiprows=1, usecols=(4, 5, 6), unpack=True)\r\n",
        "      val_loss.append(np.min(loss))\r\n",
        "      val_acc.append(acc[np.argmin(loss)])\r\n",
        "      val_f1.append(f1[np.argmin(loss)])\r\n",
        "  val_loss = np.array(val_loss)\r\n",
        "  val_acc = np.array(val_acc)\r\n",
        "  val_f1 = np.array(val_f1)\r\n",
        "\r\n",
        "\r\n",
        "  print('Acc: Mean {}, STD: {}'.format(np.mean(val_acc), np.std(val_acc)))   \r\n",
        "  print('F1: Mean {}, STD: {}'.format(np.mean(val_f1), np.std(val_f1)))   \r\n",
        "  print('Loss: Mean {}, STD: {}'.format(np.mean(val_loss), np.std(val_loss)))   \r\n",
        "\r\n",
        "  print('Best Model by loss {}, Loss: {}, Acc: {}, F1: {}'.format(np.argmin(val_loss) + 1, np.min(val_loss), val_acc[np.argmin(val_loss)], val_f1[np.argmin(val_loss)]))\r\n",
        "  print('Best Model by Acc {}, Loss: {}, Acc: {}, F1: {}'.format(np.argmax(val_acc) + 1, val_loss[np.argmax(val_acc)], np.max(val_acc), val_acc[np.argmax(val_acc)] ))\r\n",
        "  print('Best Model by F1 {}, Loss: {}, Acc: {}, F1: {}'.format(np.argmax(val_f1) + 1, val_loss[np.argmax(val_f1)], val_acc[np.argmax(val_f1)], np.max(val_f1)))\r\n",
        "\r\n",
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: Mean 0.878000009059906, STD: 0.06823488660602767\n",
            "F1: Mean 0.8882812023162842, STD: 0.08421934061250606\n",
            "Loss: Mean 0.33901224583387374, STD: 0.10429474055107064\n",
            "Best Model by loss 9, Loss: 0.20125041902065277, Acc: 0.9700000286102295, F1: 0.9765625\n",
            "Best Model by Acc 9, Loss: 0.20125041902065277, Acc: 0.9700000286102295, F1: 0.9700000286102295\n",
            "Best Model by F1 9, Loss: 0.20125041902065277, Acc: 0.9700000286102295, F1: 0.9765625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}